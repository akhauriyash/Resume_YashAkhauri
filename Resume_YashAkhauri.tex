\documentclass[]{deedy-resume-openfont}
\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%     LAST UPDATED DATE
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \lastupdated
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%     TITLE NAME
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\namesection{Yash}{Akhauri\hspace{5mm}\includegraphics[width=1.5cm, height=1.5cm]{resumeQR.png}}{
% \href{https://quirkyai.wordpress.com}{Blog  |  } 
\href{https://github.com/akhauriyash}{GitHub  |  } 
\href{https://www.linkedin.com/in/akhauriyash/}{LinkedIn  |  } 
\href{mailto:akhauri.yash@gmail.com}{akhauri.yash@gmail.com} | +91 78915 12802 
}


\section{Education}
\runsubsection{BITS Pilani}
\descript{| B.E. in Electronics and Instrumentation}
\location{Aug 2016 - May 2020 | RJ, India\\
\custombold{Fluent: Python3, PyTorch, Mathematica \\  
 Familiar: C++, Java, CUDA, OpenMP, Tensorflow, Android Studio, LibGDX, Docker}}
\sectionsep


\section{Experience}
\runsubsection{Intel}
\descript{| Research Scientist \hfill \texttt{May 2020 - Present, Bangalore, India}}
\sectionsep
\runsubsection{Xilinx Research}
\descript{| Visiting Scholar \hfill \texttt{Aug 2019 - May 2020,\quad Dublin, Ireland}}
\sectionsep
\runsubsection{Uraniom}
\descript{| Research Intern \hfill \texttt{Jan 2019 - Jul 2019,\quad  France (Remote)}}
\sectionsep
\runsubsection{Wolfram}
\descript{| Undergraduate Researcher \hfill \texttt{June 2018 - July 2018,\quad  \hspace{4pt} Massachusetts}}
\sectionsep

\section{Research}


\subsection{Papers}
\descript{LogicNets: Co-Designed Neural Networks and Circuits for Extreme-Throughput Applications \\\href{https://arxiv.org/abs/2004.03021}{\texttt{[IEEE \footnote[1]{To be published}]}} {\small Yash Akhauri*, Yaman Umuroglu*, Nicholas J. Fraser, Michaela Blott} \hfill \texttt{\emph{FPL'20} | Sweden | Sept 2020}} 
\sectionsep 
% \vspace{1mm}
\descript{High-Throughput DNN Inference with LogicNets\\\href{https://www.fccm.org/home/program/}{\texttt{[IEEE \footnote[1]{To be published}]}} {\small Yaman Umuroglu, Yash Akhauri, Nicholas J. Fraser, Michaela Blott} \hfill\texttt{\emph{FCCM'20} | AR, USA | May 2020}}
\sectionsep 
% \vspace{1mm}
\descript{HadaNets: Flexible Quantization Strategies for Neural Networks\\ \href{https://ieeexplore.ieee.org/document/9025370/}{\texttt{[IEEE]}} {\small Yash Akhauri} \hfill \texttt{\emph{CVPR'19 Workshop} | CA, USA | Jun 2019}} 
\sectionsep
% \vspace{1mm}
\descript{Exposing Hardware Building Blocks to Machine Learning Frameworks\\ \href{https://arxiv.org/abs/2004.05898}{\texttt{[ArXiv -- Bachelor's Thesis]}} {\small Yash Akhauri} \hfill \texttt{Dec 2019}} 
\sectionsep
\vspace{1mm}


\subsection{Talks}
\descript{Wolfram Technology Conference\\ {\small Speaker} \hfill \texttt{Champaign, IL | Oct. 2018}}
% \vspace{1mm}
\sectionsep
\descript{Intel AI Meetup\\ {\small Speaker} \hfill \texttt{Delhi, IN | Sept. 2018}}
% \vspace{1mm}
\sectionsep
\descript{Intel AI DevCon\\ {\small Poster} \hfill \texttt{San Francisco, Bangalore | May \& Aug 2018}}
\vspace{1mm}
\sectionsep


\subsection{Grants}
\descript{Intel Nervana Early Innovators Grant \hfill \texttt{\$5000}}
\sectionsep 
% \vspace{1mm}
\descript{Intel CVPR Travel Grant \hfill \texttt{\$3000}}
\sectionsep
% \vspace{1mm}
\descript{Wolfram Student Aid \hfill \texttt{\$2400}}
\sectionsep
% \vspace{1mm}
\descript{KVPY Scholar}
\sectionsep
% \vspace{1mm}
\descript{INSPIRE Scholarship}
% Received research grant to develop Binary Precision Neural Networks and Real time Artistic Style Transfer. The technical article can be found  \href{https://software.intel.com/en-us/articles/art-em-artistic-style-transfer-to-virtual-reality-final-update}{\texttt{[here.]}}
% The code can be found \href{https://github.com/akhauriyash/Fast-style-transfer}{\texttt{[here.]}}\\
% \sectionsep 
% \vspace{1mm}
% \descript{Intel CVPR Travel Grant \hfill \texttt{\$3000}}
% % Received a travel grant from Intel to present at the Intel Demo Booth at CVPR'19.\\
% \sectionsep
% \vspace{1mm}
% \descript{Wolfram Student Aid \hfill \texttt{\$2400}}
% Received aid to attend the Wolfram Summer School and develop Hadamard Binary Neural Networks. \\
% \sectionsep
% \vspace{1mm}
% \descript{Intel AI Meetup -- Speaker \href{https://docs.google.com/presentation/d/1PuxUM6RmDI5Dq7XgFoVWNxv_TOQ3aux8GiQ9aWlpUjg/edit?usp=sharing}{\texttt{[pptx]}} \href{https://software.intel.com/en-us/articles/developing-hadamard-neural-networks-on-the-intel-xeon-scalable-processor}{\texttt{[Article]}} \hfill \texttt{Delhi, IN | Sept. 2018}}
% Spoke about my research on scaling AI using Intel technologies. This event was organized by Intel. \\
% % \sectionsep
% % \vspace{1mm}
% % \descript{Intel AI Academy Success Story \href{https://software.intel.com/en-us/articles/developing-hadamard-neural-networks-on-the-intel-xeon-scalable-processor}{\texttt{[Link]}}}
% % Intel published a cover story of my research done in the field of Quantized Neural Networks.\\
% \sectionsep
% \vspace{1mm}
% \descript{Intel AI DevCon -- Poster \hfill \texttt{San Francisco, Bangalore | May \& Aug 2018}}
% % Presented posters on quantized GEMM kernels for Intel Xeon Phi\\
% % \sectionsep
% % \vspace{1mm}
% % \descript{KVPY Scholar}
% % Selected as a KVPY scholar by the Department of Science and Technology, Government of India. \\
% % \sectionsep
% % \descript{INSPIRE Scholarship}
% % Selected for the INSPIRE Scholarship by the Department of Science and Technology (DST), Government of India.
\clearpage
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% %     PROJECTS      
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \vspace{2mm} 
% \section{  }
% \section{Projects}
% \vspace{2mm}
% \descript{EncoderNets: Maximizing encoders, Minimizing Cache-Misses. \hfill \texttt{PyTorch}}
% Developing post-training quantization strategies to build networks for embedded devices.\\
% \sectionsep
% \vspace{1mm}
% \descript{Whitepaper - Improving distributed mesh computing with Hadamard Binary Neural Networks.}
% \href{https://docs.google.com/document/d/18uynX2yDSWm1BVCtG3Rd4CRb6xHiRxbvprUBTb4lvjY/edit?usp=sharing}{\texttt{[Link]}}\\
% \sectionsep
% \vspace{1mm}
% \descript{xGEMM \& xCONV \hfill \texttt{C++, CUDA, OpenMP}}
% Coded efficient 3D convolutional and GEMM kernels for XNOR (bit quantized) networks using CUDA C programming and OpenMP. Optimized kernels are for Intel processors and Nvidia GPUs. Invited to present a poster at Intel AI DevCon and Intel AI Student Ambassador Summit, San Francisco. The codes can be found here: \href{https://github.com/akhauriyash/XNOR-Intel-ISA}{\texttt{[OpenMP kernel]}} | \href{https://github.com/akhauriyash/XNOR-convolution}{\texttt{[CUDA kernel]}}.\\
% \sectionsep
% \vspace{1mm}
% \descript{GEMM: From Pure C to SSE Optimized Micro Kernels \hfill \texttt{C++}}
% Followed 
%  \href{http://apfel.mathematik.uni-ulm.de/~lehn/sghpc/gemm/}{\texttt{this tutorial}} to build an implementation of GEMM that achieves performance close to that of the BLIS kernels. \\
% \sectionsep
% \vspace{1mm}
% \descript{Real time artistic style transfer \hfill \texttt{Python, Tensorflow, OpenCV}}/
% \sectionsep
% \vspace{1mm}
% \descript{GravDash \hfill \texttt{Java, LibGDX, Android Studio}}
% Developed an android game using Java and libGDX as the framework. The game can be found  \href{https://play.google.com/store/apps/details?id=com.mygdx.gravtry2&hl=en}{\texttt{[here.]}}\\
% \sectionsep
% \vspace{1mm}
% \descript{Blog \hfill  \texttt{Python, Java, C++, Tensorflow, OpenMP}}
% Maintaining a \href{https://quirkyai.wordpress.com}{\texttt{[blog]}} covering various AI   related topics with over 10000 hits. \\
% \sectionsep


% \sectionsep
\end{document}
