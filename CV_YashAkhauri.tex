\documentclass[]{deedy-resume-openfont}
\begin{document}

\namesection{Yash}{Akhauri\hspace{5mm}\includegraphics[width=1.5cm, height=1.5cm]{resumeQR.png}}{
\href{https://github.com/akhauriyash}{GitHub  |  } 
\href{https://www.linkedin.com/in/akhauriyash/}{LinkedIn  |  } 
\href{mailto:akhauri.yash@gmail.com}{akhauri.yash@gmail.com} | +91 78915 12802 
}
\intro{A Research Scientist specializing in Neural Network optimization with a keen interest in Mathematics and Physics.}
\vspace{5mm}

\section{Education}
\runsubsection{BITS Pilani}
\descript{| B.E. in Electronics and Instrumentation}
\location{Aug 2016 - May 2020 | RJ, India\\
\custombold{Fluent: Python3, PyTorch, Mathematica \\  
 Familiar: C++, Java, CUDA, OpenMP, Tensorflow, Android Studio, LibGDX, Docker}}
\sectionsep
\section{Experience}

\runsubsection{Intel}
\descript{| Research Scientist \hfill \texttt{May 2020 - Present, Bangalore, India}}
\begin{tightemize}
\item Research Scientist at the Cloud Systems Research (CSR) Lab in the Systems and Software Research (SSR) Group.
\end{tightemize}
\sectionsep

\runsubsection{Xilinx Research}
\descript{| Visiting Scholar \hfill \texttt{Aug 2019 - May 2020,\quad Dublin, Ireland}}
\begin{tightemize}
\item Developed a library for co-design of neural network topologies and reconfigurable hardware that maps to an efficient FPGA implementation without the need for a custom accelerator architecture or a scheduler.
\item Targeted the Jet Substructure Classification task as part of CERN LMS L1 trigger experiments, used the library to deploy models with $10\times$ lower latency than FPGA4HEP designs.Demonstrated quantization library Brevitas to CERN \href{https://github.com/akhauriyash/FPGA4HEP-Brevitas/}{\texttt{[GitHub]}}.
\end{tightemize}

\sectionsep
\runsubsection{Uraniom}
\descript{| Research Intern \hfill \texttt{Jan 2019 - Jul 2019,\quad  France (Remote)}}
\begin{tightemize}
\item Implementing semantic segmentation models for face transfer across GIFs, progressive GANs for realistic UV map generation and explored effective weight-sharing strategies for neural networks under a research collaboration.
\end{tightemize}

\sectionsep
\runsubsection{Wolfram}
\descript{| Undergraduate Researcher \hfill \texttt{June 2018 - July 2018,\quad  \hspace{4pt} Massachusetts}}
\begin{tightemize}
\item Developed HadaNet MLPs in the Wolfram Language and worked on C OpenMP kernels for GEMM and Convolutions using the Hadamard Binarization algorithm.  \href{https://github.com/akhauriyash/XNOR-Intel-ISA}{\texttt{[OpenMP kernel]}} | \href{https://github.com/akhauriyash/XNOR-convolution}{\texttt{[CUDA kernel]}} | \href{https://docs.google.com/document/d/18uynX2yDSWm1BVCtG3Rd4CRb6xHiRxbvprUBTb4lvjY/edit?usp=sharing}{\texttt{[Whitepaper]}}
\end{tightemize}

\sectionsep

\section{Research}


\subsection{Papers}
\descript{LogicNets: Co-Designed Neural Networks and Circuits for Extreme-Throughput Applications \\\href{https://arxiv.org/abs/2004.03021}{\texttt{[IEEE \footnote[1]{To be published}]}} {\small Yash Akhauri*, Yaman Umuroglu*, Nicholas J. Fraser, Michaela Blott} \hfill \texttt{\emph{FPL'20} | Sweden | Sept 2020}} 
Paper accepted at \custombold{FCCM'20} as a poster presentation. Video presentation can be found \href{https://www.youtube.com/watch?v=jJRwyHD_UUI}{here.}\\
\sectionsep 

\descript{High-Throughput DNN Inference with LogicNets\\\href{https://www.fccm.org/home/program/}{\texttt{[IEEE \footnote[1]{To be published}]}} {\small Yaman Umuroglu, Yash Akhauri, Nicholas J. Fraser, Michaela Blott} \hfill\texttt{\emph{FCCM'20} | AR, USA | May 2020}}
\sectionsep 

\descript{HadaNets: Flexible Quantization Strategies for Neural Networks\\ \href{https://ieeexplore.ieee.org/document/9025370/}{\texttt{[IEEE]}} {\small Yash Akhauri} \hfill \texttt{\emph{CVPR'19 Workshop} | CA, USA | Jun 2019}} 
Paper accepted at \custombold{CVPR'19 UAVision workshop - Orals}. \\ 
Delivered a "Theatre Talk" and poster at the Intel Demo Booth at CVPR'19.\\
\sectionsep

\descript{Exposing Hardware Building Blocks to Machine Learning Frameworks\\ \href{https://arxiv.org/abs/2004.05898}{\texttt{[ArXiv -- Bachelor's Thesis]}} {\small Yash Akhauri} \hfill \texttt{Dec 2019}} 
\sectionsep
\vspace{1mm}

\clearpage

\subsection{Talks}
\descript{Wolfram Technology Conference\\ {\small Speaker} \hfill \texttt{Champaign, IL | Oct. 2018}}
Delivered a talk on my research on Hadamard Neural Networks. \\

\sectionsep
\descript{Intel AI Meetup\\ {\small Speaker} \hfill \texttt{Delhi, IN | Sept. 2018}}
\href{https://docs.google.com/presentation/d/1PuxUM6RmDI5Dq7XgFoVWNxv_TOQ3aux8GiQ9aWlpUjg/edit?usp=sharing}{\texttt{[PPTX]}} \href{https://software.intel.com/en-us/articles/developing-hadamard-neural-networks-on-the-intel-xeon-scalable-processor}{\texttt{[Article]}}
Spoke about my research on scaling AI using Intel technologies. This event was organized by Intel. \\

\sectionsep
\descript{Intel AI DevCon\\ {\small Poster} \hfill \texttt{San Francisco, Bangalore | May \& Aug 2018}}
Presented posters on quantized GEMM kernels for Intel Xeon Phi\\
\vspace{1mm}
\sectionsep


\subsection{Grants}

\descript{Intel Nervana Early Innovators Grant \hfill \texttt{\$5000}}
Received research grant to develop Binary Precision Neural Networks and Real time Artistic Style Transfer. The technical article can be found  \href{https://software.intel.com/en-us/articles/art-em-artistic-style-transfer-to-virtual-reality-final-update}{\texttt{[here.]}}
The code can be found \href{https://github.com/akhauriyash/Fast-style-transfer}{\texttt{[here.]}}\\
Intel AI Academy Success Story \href{https://software.intel.com/en-us/articles/developing-hadamard-neural-networks-on-the-intel-xeon-scalable-processor}{\texttt{[Link]}} published by Intel for the research done as part of this grant in the field of Quantized Neural Networks.
\sectionsep 

\descript{Intel CVPR Travel Grant \hfill \texttt{\$3000}}
Received a travel grant from Intel to present research at the Intel Demo Booth at CVPR'19.\\
\sectionsep

\descript{Wolfram Student Aid \hfill \texttt{\$2400}}
Received aid to attend the Wolfram Summer School and develop Hadamard Binary Neural Networks. \\
\sectionsep

\descript{KVPY Scholar}
Selected as a KVPY scholar by the Department of Science and Technology, Government of India. \\
\sectionsep

\descript{INSPIRE Scholarship}
Selected for the INSPIRE Scholarship by the Department of Science and Technology (DST), Government of India.\\
\vspace{1mm}
\sectionsep

\subsection{Projects}

\descript{Exploiting Huffman Coding and Weight-Sharing for Memory-Efficient Inference on FPGAs. \hfill \texttt{PyTorch}}
Developed a neural network weight sharing strategy and proposed a methodology to leverage this strategy in the FINN architecture for Multi-Layer Offload and Data-Flow Architectures of Neural Network deployment on FPGAs. \\
\sectionsep

\descript{Whitepaper - Improving distributed mesh computing with Hadamard Binary Neural Networks.}
\href{https://docs.google.com/document/d/18uynX2yDSWm1BVCtG3Rd4CRb6xHiRxbvprUBTb4lvjY/edit?usp=sharing}{\texttt{[Link]}}\\
\sectionsep

\descript{xGEMM \& xCONV \hfill \texttt{C++, CUDA, OpenMP}}
Coded efficient 3D convolutional and GEMM kernels for XNOR (bit quantized) networks using CUDA C programming and OpenMP. Optimized kernels are for Intel processors and Nvidia GPUs. Invited to present a poster at Intel AI DevCon and Intel AI Student Ambassador Summit, San Francisco. The codes can be found here: \href{https://github.com/akhauriyash/XNOR-Intel-ISA}{\texttt{[OpenMP kernel]}} | \href{https://github.com/akhauriyash/XNOR-convolution}{\texttt{[CUDA kernel]}}.\\
\sectionsep

% \descript{GEMM: From Pure C to SSE Optimized Micro Kernels \hfill \texttt{C++}}
% Followed 
%  \href{http://apfel.mathematik.uni-ulm.de/~lehn/sghpc/gemm/}{\texttt{this tutorial}} to build an implementation of GEMM that achieves performance close to that of the BLIS kernels. \\
% \sectionsep

\descript{Real time artistic style transfer \hfill \texttt{Python, Tensorflow, OpenCV}}/
\sectionsep

\descript{GravDash \hfill \texttt{Java, LibGDX, Android Studio}}
Developed an android game using Java and libGDX as the framework. \\
\sectionsep

\descript{Blog \hfill  \texttt{Python, Java, C++, Tensorflow, OpenMP}}
Maintaining a \href{https://quirkyai.wordpress.com}{\texttt{[blog]}} covering various AI   related topics with over 10000 hits. \\
\sectionsep


% \sectionsep
\end{document}
